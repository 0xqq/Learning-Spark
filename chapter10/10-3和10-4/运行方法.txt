运行方法：

第１步，启动hdfs系统
./start-dfs.sh &
－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－
第２步，首先生成假冒的网络日志用来模拟实验输入：
mkdir -p /tmp/logs
mkdir -p /tmp/outpandas
hdfs dfs -mkdir /tmp/outpandas
貌似被监控的文件在本地,那么本地的outpandas就会有结果
貌似被监控的文件在HDFS,那么HDFS的outpandas就会有结果
这个不要紧,反正我们在Intellij的终端看结果就好啦.
./fakelogs.sh
然后会在＂Linux本地系统＂的/tmp/logs路径下生成假冒的网络日志logdata.txt（因为要模仿实验结果，所以先用假的代替）
－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－
第3步,
Intellij运行(直接导入整个文件夹"10-3和10-4"即可)，run configuration中设置如下:
Main.class设置为com.scalalearn.scala.main.LogAnalyzerAppMain
VM options设置为-Dspark.master=local
等待运行稳定后,进行下一步
－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－
第4步
rm /tmp/logs/*
cp logdata.txt /tmp/logs
－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－

最终在Intellij中的实验结果：
-------------------------------------------
Time: 1534431741000 ms
-------------------------------------------
(66.249.69.97,3)
(71.19.157.174,13)

这个实验结果的意思是:
66.249.69.97  这个ip对应的客户访问了我们的网站次数为  3次
71.19.157.174这个ip对应的客户访问了我们的网站次数为13次
－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－
为什么一定要在代码运行后才能拷贝文件过去?
代码运行前拷贝文件到HDFS监测地址，则该文件属于＂静态数据＂
代码运行后拷贝文件到HDFS监测地址，则该文件属于＂动态数据＂
也可以参考以下链接：
https://blog.csdn.net/young_so_nice/article/details/51629049


附：
如果碰到namenode处于safe mode模式，那么输入：
dfsadmin -safemode leave


这个目录下的文件是这样的:
src和pom.xml用来构成整个Intellij工程.
fake_logs和fakelogs.sh用来生成logdata.txt